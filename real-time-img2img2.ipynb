{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6690,"status":"ok","timestamp":1722302434012,"user":{"displayName":"Aryanne","userId":"17738919751604825061"},"user_tz":180},"id":"NKrCe6MiGAse","outputId":"80c8243f-f2da-4250-8376-aefb7d396aac","trusted":true},"outputs":[],"source":["!git clone https://github.com/cumulo-autumn/StreamDiffusion.git\n","#!apt install python3.10-venv # Not necessary on kaggle\n","!python -m venv .venv\n","\n","!source .venv/bin/activate"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":173513,"status":"ok","timestamp":1722302607521,"user":{"displayName":"Aryanne","userId":"17738919751604825061"},"user_tz":180},"id":"YusFeMdiGxe-","outputId":"c8f6178c-8af7-4864-9178-144bd33dfcb9","trusted":true},"outputs":[],"source":["!pip3 install torch==2.1.0 torchvision==0.16.0 xformers --index-url https://download.pytorch.org/whl/cu121"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":21298,"status":"ok","timestamp":1722302628795,"user":{"displayName":"Aryanne","userId":"17738919751604825061"},"user_tz":180},"id":"75wki2ZlIb__","outputId":"51d23c66-c3fe-47c7-edd3-a8a2e54a0bca","trusted":true},"outputs":[],"source":["!pip3 install streamdiffusion[tensorrt]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DATQkSjhIytt","outputId":"fd0a06a2-34f2-439b-f93b-53726731f791","trusted":true},"outputs":[],"source":["!python -m streamdiffusion.tools.install-tensorrt"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tlWWHJzmN9W4","trusted":true},"outputs":[],"source":["# Ignore the error about Pywin2\n","# Restart the session around here and continue\n"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-07-30T20:40:12.964429Z","iopub.status.busy":"2024-07-30T20:40:12.963701Z","iopub.status.idle":"2024-07-30T20:40:12.980965Z","shell.execute_reply":"2024-07-30T20:40:12.980186Z","shell.execute_reply.started":"2024-07-30T20:40:12.964379Z"},"trusted":true},"outputs":[],"source":["# Here you can change the parameters\n","with open(\"/kaggle/working/StreamDiffusion/demo/realtime-img2img/img2img.py\", \"w\") as f:\n","    f.write('''\n","import sys\n","import os\n","sys.path.append(\n","    os.path.join(\n","        os.path.dirname(__file__),\n","        \"..\",\n","        \"..\",\n","    )\n",")\n","from utils.wrapper import StreamDiffusionWrapper\n","import torch\n","from config import Args\n","from pydantic import BaseModel, Field\n","from PIL import Image\n","import math\n","base_model = \"stabilityai/sd-turbo\"\n","taesd_model = \"madebyollin/taesd\"\n","default_prompt = \"Portrait of The Joker halloween costume, face painting, with , glare pose, detailed, intricate, full of colour, cinematic lighting, trending on artstation, 8k, hyperrealistic, focused, extreme details, unreal engine 5 cinematic, masterpiece\"\n","default_negative_prompt = \"black and white, blurry, low resolution, pixelated,  pixel art, low quality, low fidelity\"\n","page_content = r\"\"\"<h1 class='text-3xl font-bold'>StreamDiffusion</h1>\n","<h3 class='text-xl font-bold'>Image-to-Image SD-Turbo</h3>\n","<p class='text-sm'>\n","    This demo showcases\n","    <a\n","    href='https://github.com/cumulo-autumn/StreamDiffusion'\n","    target='_blank'\n","    class='text-blue-500 underline hover:no-underline'>StreamDiffusion\n","</a>\n","Image to Image pipeline using\n","    <a\n","    href='https://huggingface.co/stabilityai/sd-turbo'\n","    target='_blank'\n","    class='text-blue-500 underline hover:no-underline'>SD-Turbo</a\n","    > with a MJPEG stream server.\n","</p>\n","\"\"\"\n","class Pipeline:\n","    class Info(BaseModel):\n","        name: str = \"StreamDiffusion img2img\"\n","        input_mode: str = \"image\"\n","        page_content: str = page_content\n","    class InputParams(BaseModel):\n","        prompt: str = Field(\n","            default_prompt,\n","            title=\"Prompt\",\n","            field=\"textarea\",\n","            id=\"prompt\",\n","        )\n","        negative_prompt: str = Field(\n","             default_negative_prompt,\n","             title=\"Negative Prompt\",\n","             field=\"textarea\",\n","             id=\"negative_prompt\",\n","        )\n","        width: int = Field(\n","            512, min=2, max=15, title=\"Width\", disabled=True, hide=True, id=\"width\"\n","        )\n","        height: int = Field(\n","            512, min=2, max=15, title=\"Height\", disabled=True, hide=True, id=\"height\"\n","        )\n","    def __init__(self, args: Args, device: torch.device, torch_dtype: torch.dtype):\n","        params = self.InputParams()\n","        self.stream = StreamDiffusionWrapper(\n","            model_id_or_path=base_model,\n","            use_tiny_vae=args.taesd,\n","            device=device,\n","            dtype=torch_dtype,\n","            t_index_list=[35, 45],\n","            frame_buffer_size=1,\n","            width=params.width,\n","            height=params.height,\n","            use_lcm_lora=False,\n","            output_type=\"pil\",\n","            warmup=10,\n","            vae_id=None,\n","            acceleration=args.acceleration,\n","            mode=\"img2img\",\n","            use_denoising_batch=True,\n","            cfg_type=\"none\",\n","            use_safety_checker=args.safety_checker,\n","            # enable_similar_image_filter=True,\n","            # similar_image_filter_threshold=0.98,\n","            engine_dir=args.engine_dir,\n","        )\n","        self.last_prompt = default_prompt\n","        self.stream.prepare(\n","            prompt=default_prompt,\n","            negative_prompt=default_negative_prompt,\n","            num_inference_steps=50,\n","            guidance_scale=2.0,\n","        )\n","    def predict(self, params: \"Pipeline.InputParams\") -> Image.Image:\n","        image_tensor = self.stream.preprocess_image(params.image)\n","        output_image = self.stream(image=image_tensor, prompt=params.prompt)\n","        return output_image\n","''')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XLHqU23ILsm9","outputId":"e75616f4-6d0c-46a8-ac14-608584845963","trusted":true},"outputs":[],"source":["%cd /kaggle/working/StreamDiffusion/demo/realtime-img2img/frontend\n","!npm i\n","!npm run build\n","%cd ..\n","!pip install -r requirements.txt\n","\n","!pip install pyngrok\n","from pyngrok import ngrok\n","\n","# Set your ngrok token\n","!ngrok config add-authtoken here\n","\n","import threading\n","\n","def run():\n","    public_url = ngrok.connect(7860)\n","    print(f\"ngrok URL: {public_url}\")\n","\n","def main():\n","\n","    minha_thread = threading.Thread(target=run)\n","    minha_thread.start()\n","    !python main.py --acceleration tensorrt \n","    \n","\n","if __name__ == \"__main__\":\n","    main()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IrPsInRwLvDX"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30747,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
